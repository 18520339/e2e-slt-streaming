{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7WsfAvF6PBf"
      },
      "source": [
        "### Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AhZOc3Y-eV4d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from typing import List\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "\n",
        "from enum import Enum\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from huggingface_hub import hf_hub_download, hf_hub_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8aB8rOiuci4"
      },
      "source": [
        "### Pose Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ai1Ychruuci4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file  \n",
            "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\dangh\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "@dataclass\n",
        "class DetectorConfig:\n",
        "    model_path: str = \"models/yolov8m.pt\"\n",
        "    person_id: int = 0\n",
        "    conf_thres: float = 0.25\n",
        "\n",
        "\n",
        "def draw_boxes(img, boxes, color=(0, 255, 0), thickness=2):\n",
        "    draw_img = img.copy()\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        draw_img = cv2.rectangle(draw_img, (x1, y1), (x2, y2), color, thickness)\n",
        "    return draw_img\n",
        "\n",
        "\n",
        "class Detector:\n",
        "    def __init__(self, config: DetectorConfig = DetectorConfig()):\n",
        "        model_path = config.model_path\n",
        "        if not model_path.endswith(\".pt\"):\n",
        "            model_path = model_path.split(\".\")[0] + \".pt\"\n",
        "        self.model = YOLO(model_path, verbose=False)\n",
        "        self.person_id = config.person_id\n",
        "        self.conf_thres = config.conf_thres\n",
        "\n",
        "    def __call__(self, img: np.ndarray) -> np.ndarray:\n",
        "        return self.detect(img)\n",
        "\n",
        "    def detect(self, img: np.ndarray) -> np.ndarray:\n",
        "        start = time.perf_counter()\n",
        "        results = self.model(img, conf=self.conf_thres)\n",
        "        detections = results[0].boxes.data.cpu().numpy()  # (x1, y1, x2, y2, conf, cls)\n",
        "\n",
        "        # Filter out only person\n",
        "        person_detections = detections[detections[:, -1] == self.person_id]\n",
        "        boxes = person_detections[:, :-2].astype(int)\n",
        "\n",
        "        # print(f\"Detection inference took: {time.perf_counter() - start:.4f} seconds\")\n",
        "        return boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3-ljpYFAuci4"
      },
      "outputs": [],
      "source": [
        "from classes_and_palettes import (\n",
        "    COCO_KPTS_COLORS,\n",
        "    COCO_WHOLEBODY_KPTS_COLORS,\n",
        "    GOLIATH_KPTS_COLORS,\n",
        "    GOLIATH_SKELETON_INFO,\n",
        "    GOLIATH_KEYPOINTS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZXFjEhnuci4"
      },
      "outputs": [],
      "source": [
        "class SapiensPoseEstimation:\n",
        "    def __init__(self,\n",
        "                 path='sapiens_1b_goliath_best_goliath_AP_639_torchscript.pt2',\n",
        "                 device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                 dtype: torch.dtype = torch.float32):\n",
        "        # Load the model\n",
        "        self.device = device\n",
        "        self.dtype = dtype\n",
        "        self.model = torch.jit.load(path).eval().to(device).to(dtype)\n",
        "        self.preprocessor = transforms.Compose([transforms.ToPILImage(),\n",
        "                               transforms.Resize((1024,768)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "                               ])\n",
        "        # Initialize the YOLO-based detector\n",
        "        self.detector = Detector()\n",
        "\n",
        "\n",
        "    def __call__(self, img: np.ndarray) -> np.ndarray:\n",
        "        start = time.perf_counter()\n",
        "\n",
        "        # Detect persons in the image\n",
        "        bboxes = self.detector.detect(img)\n",
        "\n",
        "        # Process the image and estimate the pose\n",
        "        pose_result_image, keypoints = self.estimate_pose(img, bboxes)\n",
        "\n",
        "        # print(f\"Pose estimation inference took: {time.perf_counter() - start:.4f} seconds\")\n",
        "        return pose_result_image, keypoints\n",
        "\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def estimate_pose(self, img: np.ndarray, bboxes: List[List[float]]) -> (np.ndarray, List[dict]):\n",
        "        all_keypoints = []\n",
        "        result_img = img.copy()\n",
        "\n",
        "        for bbox in bboxes:\n",
        "            cropped_img = self.crop_image(img, bbox)\n",
        "            tensor = self.preprocessor(cropped_img).unsqueeze(0).to(self.device).to(self.dtype)\n",
        "\n",
        "            heatmaps = self.model(tensor)\n",
        "            keypoints = self.heatmaps_to_keypoints(heatmaps[0].cpu().numpy())\n",
        "            all_keypoints.append(keypoints)\n",
        "\n",
        "            # Draw the keypoints on the original image\n",
        "            result_img = self.draw_keypoints(result_img, keypoints, bbox)\n",
        "\n",
        "        return result_img, all_keypoints\n",
        "\n",
        "    def crop_image(self, img: np.ndarray, bbox: List[float]) -> np.ndarray:\n",
        "        x1, y1, x2, y2 = map(int, bbox[:4])\n",
        "        return img[y1:y2, x1:x2]\n",
        "\n",
        "\n",
        "    def heatmaps_to_keypoints(self, heatmaps: np.ndarray) -> dict:\n",
        "        keypoints = {}\n",
        "        for i, name in enumerate(GOLIATH_KEYPOINTS):\n",
        "            if i < heatmaps.shape[0]:\n",
        "                y, x = np.unravel_index(np.argmax(heatmaps[i]), heatmaps[i].shape)\n",
        "                conf = heatmaps[i, y, x]\n",
        "                keypoints[name] = (float(x), float(y), float(conf))\n",
        "        return keypoints\n",
        "\n",
        "\n",
        "    def draw_keypoints(self, img: np.ndarray, keypoints: dict, bbox: List[float]) -> np.ndarray:\n",
        "        x1, y1, x2, y2 = map(int, bbox[:4])\n",
        "        bbox_width, bbox_height = x2 - x1, y2 - y1\n",
        "        img_copy = img.copy()\n",
        "\n",
        "        # Draw keypoints on the image\n",
        "        for i, (name, (x, y, conf)) in enumerate(keypoints.items()):\n",
        "            if conf > 0.3:  # Only draw confident keypoints\n",
        "                x_coord = int(x * bbox_width / 192) + x1\n",
        "                y_coord = int(y * bbox_height / 256) + y1\n",
        "                cv2.circle(img_copy, (x_coord, y_coord), 3, GOLIATH_KPTS_COLORS[i], -1)\n",
        "\n",
        "        # Optionally draw skeleton\n",
        "        for _, link_info in GOLIATH_SKELETON_INFO.items():\n",
        "            pt1_name, pt2_name = link_info['link']\n",
        "            if pt1_name in keypoints and pt2_name in keypoints:\n",
        "                pt1 = keypoints[pt1_name]\n",
        "                pt2 = keypoints[pt2_name]\n",
        "                if pt1[2] > 0.3 and pt2[2] > 0.3:\n",
        "                    x1_coord = int(pt1[0] * bbox_width / 192) + x1\n",
        "                    y1_coord = int(pt1[1] * bbox_height / 256) + y1\n",
        "                    x2_coord = int(pt2[0] * bbox_width / 192) + x1\n",
        "                    y2_coord = int(pt2[1] * bbox_height / 256) + y1\n",
        "                    cv2.line(img_copy, (x1_coord, y1_coord), (x2_coord, y2_coord), GOLIATH_KPTS_COLORS[i], 2)\n",
        "\n",
        "        return img_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "dHEeTh7-uci4",
        "outputId": "10179eed-9bb5-474d-cf6f-675e665115d0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pose_estimator = SapiensPoseEstimation()\n",
        "\n",
        "img_path = \"football.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "start_time = time.perf_counter()\n",
        "result_img, keypoints = pose_estimator(img)\n",
        "\n",
        "height, width, _ = result_img.shape\n",
        "fig = plt.figure(figsize = (width/100, height/100), dpi=100)\n",
        "print(f\"Time taken: {time.perf_counter() - start_time:.4f} seconds\")\n",
        "\n",
        "result_img_rgb = result_img[:,:,::-1]\n",
        "plt.imshow(result_img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "del pose_estimator\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0jLCNGCqQEiU",
        "outputId": "9da48e1d-694c-4b40-f5f9-490d588059e3"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "pose_estimator = SapiensPoseEstimation(dtype=torch.float16)\n",
        "cap = cv2.VideoCapture(\"test_images/Sapiens-video-test.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret: break\n",
        "\n",
        "    result_img, _, _  = pose_estimator(frame)\n",
        "    cv2_imshow(result_img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "    torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
